{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00f29b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install git+https://github.com/openai/whisper.git -q  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27332fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: moviepy in d:\\pago\\jupyter\\lib\\site-packages (1.0.3)\n",
      "Requirement already satisfied: gtts in d:\\pago\\jupyter\\lib\\site-packages (2.5.0)\n",
      "Requirement already satisfied: googletrans in d:\\pago\\jupyter\\lib\\site-packages (3.0.0)\n",
      "Requirement already satisfied: decorator<5.0,>=4.0.2 in d:\\pago\\jupyter\\lib\\site-packages (from moviepy) (4.4.2)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.11.2 in d:\\pago\\jupyter\\lib\\site-packages (from moviepy) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.8.1 in d:\\pago\\jupyter\\lib\\site-packages (from moviepy) (2.31.0)\n",
      "Requirement already satisfied: proglog<=1.0.0 in d:\\pago\\jupyter\\lib\\site-packages (from moviepy) (0.1.10)\n",
      "Requirement already satisfied: numpy>=1.17.3 in d:\\pago\\jupyter\\lib\\site-packages (from moviepy) (1.24.3)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in d:\\pago\\jupyter\\lib\\site-packages (from moviepy) (2.26.0)\n",
      "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in d:\\pago\\jupyter\\lib\\site-packages (from moviepy) (0.4.9)\n",
      "Requirement already satisfied: click<8.2,>=7.1 in d:\\pago\\jupyter\\lib\\site-packages (from gtts) (8.0.4)\n",
      "Requirement already satisfied: httpx==0.13.3 in d:\\pago\\jupyter\\lib\\site-packages (from googletrans) (0.13.3)\n",
      "Requirement already satisfied: certifi in d:\\pago\\jupyter\\lib\\site-packages (from httpx==0.13.3->googletrans) (2023.7.22)\n",
      "Requirement already satisfied: hstspreload in d:\\pago\\jupyter\\lib\\site-packages (from httpx==0.13.3->googletrans) (2024.1.5)\n",
      "Requirement already satisfied: sniffio in d:\\pago\\jupyter\\lib\\site-packages (from httpx==0.13.3->googletrans) (1.2.0)\n",
      "Requirement already satisfied: chardet==3.* in d:\\pago\\jupyter\\lib\\site-packages (from httpx==0.13.3->googletrans) (3.0.4)\n",
      "Requirement already satisfied: idna==2.* in d:\\pago\\jupyter\\lib\\site-packages (from httpx==0.13.3->googletrans) (2.10)\n",
      "Requirement already satisfied: rfc3986<2,>=1.3 in d:\\pago\\jupyter\\lib\\site-packages (from httpx==0.13.3->googletrans) (1.5.0)\n",
      "Requirement already satisfied: httpcore==0.9.* in d:\\pago\\jupyter\\lib\\site-packages (from httpx==0.13.3->googletrans) (0.9.1)\n",
      "Requirement already satisfied: h11<0.10,>=0.8 in d:\\pago\\jupyter\\lib\\site-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans) (0.9.0)\n",
      "Requirement already satisfied: h2==3.* in d:\\pago\\jupyter\\lib\\site-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans) (3.2.0)\n",
      "Requirement already satisfied: hyperframe<6,>=5.2.0 in d:\\pago\\jupyter\\lib\\site-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans) (5.2.0)\n",
      "Requirement already satisfied: hpack<4,>=3.0 in d:\\pago\\jupyter\\lib\\site-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans) (3.0.0)\n",
      "Requirement already satisfied: colorama in d:\\pago\\jupyter\\lib\\site-packages (from click<8.2,>=7.1->gtts) (0.4.6)\n",
      "Requirement already satisfied: pillow>=8.3.2 in d:\\pago\\jupyter\\lib\\site-packages (from imageio<3.0,>=2.5->moviepy) (9.4.0)\n",
      "Requirement already satisfied: setuptools in d:\\pago\\jupyter\\lib\\site-packages (from imageio-ffmpeg>=0.2.0->moviepy) (68.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\pago\\jupyter\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\pago\\jupyter\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (1.26.16)\n"
     ]
    }
   ],
   "source": [
    "!pip install moviepy gtts googletrans "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffff39fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwhisper\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogletrans\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Translator\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgtts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gTTS\n\u001b[0;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m whisper\u001b[38;5;241m.\u001b[39mload_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbase\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\PAGO\\jupyter\\Lib\\site-packages\\googletrans\\__init__.py:6\u001b[0m\n\u001b[0;32m      2\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTranslator\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      3\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m4.0.0-rc.1\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogletrans\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Translator\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogletrans\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LANGCODES, LANGUAGES\n",
      "File \u001b[1;32mD:\\PAGO\\jupyter\\Lib\\site-packages\\googletrans\\client.py:13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mhttpcore\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mhttpx\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhttpx\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Timeout\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogletrans\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m urls, utils\n",
      "File \u001b[1;32mD:\\PAGO\\jupyter\\Lib\\site-packages\\httpx\\__init__.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__version__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __description__, __title__, __version__\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m delete, get, head, options, patch, post, put, request, stream\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_auth\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Auth, BasicAuth, DigestAuth\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_client\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AsyncClient, Client\n",
      "File \u001b[1;32mD:\\PAGO\\jupyter\\Lib\\site-packages\\httpx\\_api.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_client\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Client, StreamContextManager\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DEFAULT_TIMEOUT_CONFIG\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Request, Response\n",
      "File \u001b[1;32mD:\\PAGO\\jupyter\\Lib\\site-packages\\httpx\\_client.py:8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mhstspreload\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mhttpcore\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_auth\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Auth, BasicAuth, FunctionAuth\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     10\u001b[0m     DEFAULT_MAX_REDIRECTS,\n\u001b[0;32m     11\u001b[0m     DEFAULT_POOL_LIMITS,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m     UnsetType,\n\u001b[0;32m     19\u001b[0m )\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_content_streams\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ContentStream\n",
      "File \u001b[1;32mD:\\PAGO\\jupyter\\Lib\\site-packages\\httpx\\_auth.py:10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrequest\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse_http_list\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_exceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ProtocolError, RequestBodyUnavailable\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Request, Response\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_bytes, to_str, unquote\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mAuth\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\PAGO\\jupyter\\Lib\\site-packages\\httpx\\_models.py:34\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_decoders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     17\u001b[0m     SUPPORTED_DECODERS,\n\u001b[0;32m     18\u001b[0m     Decoder,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     22\u001b[0m     TextDecoder,\n\u001b[0;32m     23\u001b[0m )\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_exceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     25\u001b[0m     CookieConflict,\n\u001b[0;32m     26\u001b[0m     HTTPError,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     32\u001b[0m     StreamConsumed,\n\u001b[0;32m     33\u001b[0m )\n\u001b[1;32m---> 34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_status_codes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StatusCode\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_types\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     36\u001b[0m     CookieTypes,\n\u001b[0;32m     37\u001b[0m     HeaderTypes,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     42\u001b[0m     URLTypes,\n\u001b[0;32m     43\u001b[0m )\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     45\u001b[0m     ElapsedTimer,\n\u001b[0;32m     46\u001b[0m     flatten_queryparams,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     54\u001b[0m     warn_deprecated,\n\u001b[0;32m     55\u001b[0m )\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1147\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:690\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:936\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1032\u001b[0m, in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1130\u001b[0m, in \u001b[0;36mget_data\u001b[1;34m(self, path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import os\n",
    "from googletrans import Translator\n",
    "from gtts import gTTS\n",
    "\n",
    "\n",
    "model = whisper.load_model(\"base\")\n",
    "\n",
    "# Define a list of target languages\n",
    "target_languages = ['te', 'fr', 'hi', 'de']  # Add more languages as needed\n",
    "\n",
    "def translate_audio(audio_file,output_audio_file_location,langauge):\n",
    "    # Load audio file\n",
    "    with io.open(audio_file, \"rb\") as audio_file:\n",
    "        content = audio_file.read()\n",
    "        audio = speech.RecognitionAudio(content=content)\n",
    "    audio = whisper.load_audio(audio)\n",
    "    print(\"audio loaded\")\n",
    "    audio = whisper.pad_or_trim(audio)\n",
    "\n",
    "    # Extract features\n",
    "    mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
    "    print(\"extracted features\")\n",
    "    # Detect language\n",
    "    _, probs = model.detect_language(mel)\n",
    "    detected_language = max(probs, key=probs.get)\n",
    "    print(f\"Detected language for {os.path.basename(audio_file)}: {detected_language}\")\n",
    "\n",
    "    # Decode and print result\n",
    "    options = whisper.DecodingOptions(fp16=False)\n",
    "    result = whisper.decode(model, mel, options)\n",
    "    print(f\"Result for {os.path.basename(audio_file)}: {result.text}\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # Translate and save audio for each target language\n",
    "    \n",
    "    translator = Translator()\n",
    "    translated_result = translator.translate(result.text, src='en', dest=langauge)\n",
    "    translated_text = translated_result.text\n",
    "\n",
    "    # Save translated text as an audio file\n",
    "    tts = gTTS(translated_text, lang=langauge)\n",
    "    tts.save(output_audio_file_location)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6033b34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: librosa in d:\\pago\\jupyter\\lib\\site-packages (0.10.1)\n",
      "Requirement already satisfied: flask in d:\\pago\\jupyter\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy in d:\\pago\\jupyter\\lib\\site-packages (1.24.3)\n",
      "Requirement already satisfied: tqdm in d:\\pago\\jupyter\\lib\\site-packages (4.65.0)\n",
      "Requirement already satisfied: torch in d:\\pago\\jupyter\\lib\\site-packages (2.1.2)\n",
      "Requirement already satisfied: moviepy in d:\\pago\\jupyter\\lib\\site-packages (1.0.3)\n",
      "Requirement already satisfied: audioread>=2.1.9 in d:\\pago\\jupyter\\lib\\site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: scipy>=1.2.0 in d:\\pago\\jupyter\\lib\\site-packages (from librosa) (1.11.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in d:\\pago\\jupyter\\lib\\site-packages (from librosa) (1.3.0)\n",
      "Requirement already satisfied: joblib>=0.14 in d:\\pago\\jupyter\\lib\\site-packages (from librosa) (1.2.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in d:\\pago\\jupyter\\lib\\site-packages (from librosa) (4.4.2)\n",
      "Requirement already satisfied: numba>=0.51.0 in d:\\pago\\jupyter\\lib\\site-packages (from librosa) (0.57.1)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in d:\\pago\\jupyter\\lib\\site-packages (from librosa) (0.12.1)\n",
      "Requirement already satisfied: pooch>=1.0 in d:\\pago\\jupyter\\lib\\site-packages (from librosa) (1.8.0)\n",
      "Requirement already satisfied: soxr>=0.3.2 in d:\\pago\\jupyter\\lib\\site-packages (from librosa) (0.3.7)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in d:\\pago\\jupyter\\lib\\site-packages (from librosa) (4.7.1)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in d:\\pago\\jupyter\\lib\\site-packages (from librosa) (0.2)\n",
      "Requirement already satisfied: msgpack>=1.0 in d:\\pago\\jupyter\\lib\\site-packages (from librosa) (1.0.3)\n",
      "Requirement already satisfied: Werkzeug>=2.2.2 in d:\\pago\\jupyter\\lib\\site-packages (from flask) (2.2.3)\n",
      "Requirement already satisfied: Jinja2>=3.0 in d:\\pago\\jupyter\\lib\\site-packages (from flask) (3.1.2)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in d:\\pago\\jupyter\\lib\\site-packages (from flask) (2.0.1)\n",
      "Requirement already satisfied: click>=8.0 in d:\\pago\\jupyter\\lib\\site-packages (from flask) (8.0.4)\n",
      "Requirement already satisfied: colorama in d:\\pago\\jupyter\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: filelock in d:\\pago\\jupyter\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: sympy in d:\\pago\\jupyter\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in d:\\pago\\jupyter\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: fsspec in d:\\pago\\jupyter\\lib\\site-packages (from torch) (2023.4.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.8.1 in d:\\pago\\jupyter\\lib\\site-packages (from moviepy) (2.31.0)\n",
      "Requirement already satisfied: proglog<=1.0.0 in d:\\pago\\jupyter\\lib\\site-packages (from moviepy) (0.1.10)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in d:\\pago\\jupyter\\lib\\site-packages (from moviepy) (2.26.0)\n",
      "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in d:\\pago\\jupyter\\lib\\site-packages (from moviepy) (0.4.9)\n",
      "Requirement already satisfied: pillow>=8.3.2 in d:\\pago\\jupyter\\lib\\site-packages (from imageio<3.0,>=2.5->moviepy) (9.4.0)\n",
      "Requirement already satisfied: setuptools in d:\\pago\\jupyter\\lib\\site-packages (from imageio-ffmpeg>=0.2.0->moviepy) (68.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\pago\\jupyter\\lib\\site-packages (from Jinja2>=3.0->flask) (2.1.1)\n",
      "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in d:\\pago\\jupyter\\lib\\site-packages (from numba>=0.51.0->librosa) (0.40.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in d:\\pago\\jupyter\\lib\\site-packages (from pooch>=1.0->librosa) (3.10.0)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\pago\\jupyter\\lib\\site-packages (from pooch>=1.0->librosa) (23.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\pago\\jupyter\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\pago\\jupyter\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\pago\\jupyter\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\pago\\jupyter\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (2023.7.22)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\pago\\jupyter\\lib\\site-packages (from scikit-learn>=0.20.0->librosa) (2.2.0)\n",
      "Requirement already satisfied: cffi>=1.0 in d:\\pago\\jupyter\\lib\\site-packages (from soundfile>=0.12.1->librosa) (1.15.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in d:\\pago\\jupyter\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: pycparser in d:\\pago\\jupyter\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n"
     ]
    }
   ],
   "source": [
    "!pip install librosa flask numpy tqdm torch moviepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63b34f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu for inference.\n"
     ]
    }
   ],
   "source": [
    "from os import listdir, path\n",
    "import numpy as np\n",
    "import scipy, cv2, os, sys, argparse, audio\n",
    "import json, subprocess, random, string\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import torch, face_detection\n",
    "from models import Wav2Lip\n",
    "import platform\n",
    "\n",
    "import json\n",
    "\n",
    "args = {\n",
    "    'checkpoint_path': \"D:/PAGO/Wav2Lip/checkpoints/wav2lip.pth\",\n",
    "    'face': \"D:/PAGO/Wav2Lip/media/uploaded_video/uploaded.mp4\",\n",
    "    'audio': \"D:/PAGO/Wav2Lip/media/uploaded_audio/uploaded.wav\",\n",
    "    'outfile': \"D:/PAGO/Wav2Lip/results/video.mp4\",\n",
    "    'static': False,\n",
    "    'fps': 25.,\n",
    "    'pads': [0, 10, 0, 0],\n",
    "    'face_det_batch_size': 16,\n",
    "    'wav2lip_batch_size': 128,\n",
    "    'resize_factor': 1,\n",
    "    'crop': [0, -1, 0, -1],\n",
    "    'box': [-1, -1, -1, -1],\n",
    "    'rotate': False,\n",
    "    'nosmooth': False,\n",
    "    'img_size': 96\n",
    "}\n",
    "\n",
    "# Save the dictionary as a JSON file\n",
    "with open('args.json', 'w') as json_file:\n",
    "    json.dump(args, json_file)\n",
    "\n",
    "\n",
    "if os.path.isfile(args['face']) and args['face'].split('.')[1] in ['jpg', 'png', 'jpeg']:\n",
    "\targs['static'] = True\n",
    "\n",
    "def get_smoothened_boxes(boxes, T):\n",
    "\tfor i in range(len(boxes)):\n",
    "\t\tif i + T > len(boxes):\n",
    "\t\t\twindow = boxes[len(boxes) - T:]\n",
    "\t\telse:\n",
    "\t\t\twindow = boxes[i : i + T]\n",
    "\t\tboxes[i] = np.mean(window, axis=0)\n",
    "\treturn boxes\n",
    "\n",
    "def face_detect(images):\n",
    "\tdetector = face_detection.FaceAlignment(face_detection.LandmarksType._2D, \n",
    "\t\t\t\t\t\t\t\t\t\t\tflip_input=False, device=device)\n",
    "\n",
    "\tbatch_size = args['face_det_batch_size']\n",
    "\t\n",
    "\twhile 1:\n",
    "\t\tpredictions = []\n",
    "\t\ttry:\n",
    "\t\t\tfor i in tqdm(range(0, len(images), batch_size)):\n",
    "\t\t\t\tpredictions.extend(detector.get_detections_for_batch(np.array(images[i:i + batch_size])))\n",
    "\t\texcept RuntimeError:\n",
    "\t\t\tif batch_size == 1: \n",
    "\t\t\t\traise RuntimeError('Image too big to run face detection on GPU. Please use the --resize_factor argument')\n",
    "\t\t\tbatch_size //= 2\n",
    "\t\t\tprint('Recovering from OOM error; New batch size: {}'.format(batch_size))\n",
    "\t\t\tcontinue\n",
    "\t\tbreak\n",
    "\n",
    "\tresults = []\n",
    "\tpady1, pady2, padx1, padx2 = args['pads']\n",
    "\tfor rect, image in zip(predictions, images):\n",
    "\t\tif rect is None:\n",
    "\t\t\tcv2.imwrite('temp/faulty_frame.jpg', image) # check this frame where the face was not detected.\n",
    "\t\t\traise ValueError('Face not detected! Ensure the video contains a face in all the frames.')\n",
    "\n",
    "\t\ty1 = max(0, rect[1] - pady1)\n",
    "\t\ty2 = min(image.shape[0], rect[3] + pady2)\n",
    "\t\tx1 = max(0, rect[0] - padx1)\n",
    "\t\tx2 = min(image.shape[1], rect[2] + padx2)\n",
    "\t\t\n",
    "\t\tresults.append([x1, y1, x2, y2])\n",
    "\n",
    "\tboxes = np.array(results)\n",
    "\tif not args['nosmooth']: boxes = get_smoothened_boxes(boxes, T=5)\n",
    "\tresults = [[image[y1: y2, x1:x2], (y1, y2, x1, x2)] for image, (x1, y1, x2, y2) in zip(images, boxes)]\n",
    "\n",
    "\tdel detector\n",
    "\treturn results \n",
    "\n",
    "def datagen(frames, mels):\n",
    "\timg_batch, mel_batch, frame_batch, coords_batch = [], [], [], []\n",
    "\n",
    "\tif args.box[0] == -1:\n",
    "\t\tif not args['static']:\n",
    "\t\t\tface_det_results = face_detect(frames) # BGR2RGB for CNN face detection\n",
    "\t\telse:\n",
    "\t\t\tface_det_results = face_detect([frames[0]])\n",
    "\telse:\n",
    "\t\tprint('Using the specified bounding box instead of face detection...')\n",
    "\t\ty1, y2, x1, x2 = args['box']\n",
    "\t\tface_det_results = [[f[y1: y2, x1:x2], (y1, y2, x1, x2)] for f in frames]\n",
    "\n",
    "\tfor i, m in enumerate(mels):\n",
    "\t\tidx = 0 if args['static'] else i%len(frames)\n",
    "\t\tframe_to_save = frames[idx].copy()\n",
    "\t\tface, coords = face_det_results[idx].copy()\n",
    "\n",
    "\t\tface = cv2.resize(face, (args['img_size'], args['img_size']))\n",
    "\t\t\t\n",
    "\t\timg_batch.append(face)\n",
    "\t\tmel_batch.append(m)\n",
    "\t\tframe_batch.append(frame_to_save)\n",
    "\t\tcoords_batch.append(coords)\n",
    "\n",
    "\t\tif len(img_batch) >= args['wav2lip_batch_size']:\n",
    "\t\t\timg_batch, mel_batch = np.asarray(img_batch), np.asarray(mel_batch)\n",
    "\n",
    "\t\t\timg_masked = img_batch.copy()\n",
    "\t\t\timg_masked[:, args['img_size']//2:] = 0\n",
    "\n",
    "\t\t\timg_batch = np.concatenate((img_masked, img_batch), axis=3) / 255.\n",
    "\t\t\tmel_batch = np.reshape(mel_batch, [len(mel_batch), mel_batch.shape[1], mel_batch.shape[2], 1])\n",
    "\n",
    "\t\t\tyield img_batch, mel_batch, frame_batch, coords_batch\n",
    "\t\t\timg_batch, mel_batch, frame_batch, coords_batch = [], [], [], []\n",
    "\n",
    "\tif len(img_batch) > 0:\n",
    "\t\timg_batch, mel_batch = np.asarray(img_batch), np.asarray(mel_batch)\n",
    "\n",
    "\t\timg_masked = img_batch.copy()\n",
    "\t\timg_masked[:, args['img_size']//2:] = 0\n",
    "\n",
    "\t\timg_batch = np.concatenate((img_masked, img_batch), axis=3) / 255.\n",
    "\t\tmel_batch = np.reshape(mel_batch, [len(mel_batch), mel_batch.shape[1], mel_batch.shape[2], 1])\n",
    "\n",
    "\t\tyield img_batch, mel_batch, frame_batch, coords_batch\n",
    "\n",
    "mel_step_size = 16\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} for inference.'.format(device))\n",
    "\n",
    "def _load(checkpoint_path):\n",
    "\tif device == 'cuda':\n",
    "\t\tcheckpoint = torch.load(checkpoint_path)\n",
    "\telse:\n",
    "\t\tcheckpoint = torch.load(checkpoint_path,\n",
    "\t\t\t\t\t\t\t\tmap_location=lambda storage, loc: storage)\n",
    "\treturn checkpoint\n",
    "\n",
    "def load_model(path):\n",
    "\tmodel = Wav2Lip()\n",
    "\tprint(\"Load checkpoint from: {}\".format(path))\n",
    "\tcheckpoint = _load(path)\n",
    "\ts = checkpoint[\"state_dict\"]\n",
    "\tnew_s = {}\n",
    "\tfor k, v in s.items():\n",
    "\t\tnew_s[k.replace('module.', '')] = v\n",
    "\tmodel.load_state_dict(new_s)\n",
    "\n",
    "\tmodel = model.to(device)\n",
    "\treturn model.eval()\n",
    "\n",
    "def convert(audio_file, video_file, checkpoint_path, final_output_directory):\n",
    "    args['face'] = video_file\n",
    "    args['audio'] = audio_file\n",
    "    args['checkpoint_path'] = checkpoint_path\n",
    "    print(\"generating video\")\n",
    "    if not os.path.isfile(args['face']):\n",
    "        raise ValueError('--face argument must be a valid path to video/image file')\n",
    "\n",
    "    elif args['face'].split('.')[1] in ['jpg', 'png', 'jpeg']:\n",
    "        full_frames = [cv2.imread(args['face'])]\n",
    "        fps = args['fps']\n",
    "\n",
    "    else:\n",
    "        video_stream = cv2.VideoCapture(args['face'])\n",
    "        fps = video_stream.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "        print('Reading video frames...')\n",
    "\n",
    "        full_frames = []\n",
    "        while 1:\n",
    "            still_reading, frame = video_stream.read()\n",
    "            if not still_reading:\n",
    "                video_stream.release()\n",
    "                break\n",
    "            if args['resize_factor'] > 1:\n",
    "                frame = cv2.resize(frame, (frame.shape[1] // args['resize_factor'], frame.shape[0] // args['resize_factor']))\n",
    "\n",
    "            if args['rotate']:\n",
    "                frame = cv2.rotate(frame, cv2.cv2.ROTATE_90_CLOCKWISE)\n",
    "\n",
    "            y1, y2, x1, x2 = args['crop']\n",
    "            if x2 == -1: x2 = frame.shape[1]\n",
    "            if y2 == -1: y2 = frame.shape[0]\n",
    "\n",
    "            frame = frame[y1:y2, x1:x2]\n",
    "\n",
    "            full_frames.append(frame)\n",
    "\n",
    "    print(\"Number of frames available for inference: \" + str(len(full_frames)))\n",
    "\n",
    "    if not args['audio'].endswith('.wav'):\n",
    "        print('Extracting raw audio...')\n",
    "        command = 'ffmpeg -y -i {} -strict -2 {}'.format(args['audio'], 'temp/temp.wav')\n",
    "\n",
    "        subprocess.call(command, shell=True)\n",
    "        args['audio'] = 'temp/temp.wav'\n",
    "    print(\"original audio\")\n",
    "    wav = audio.load_wav(args['audio'], 16000)\n",
    "    mel = audio.melspectrogram(wav)\n",
    "    print(mel.shape)\n",
    "\n",
    "    if np.isnan(mel.reshape(-1)).sum() > 0:\n",
    "        raise ValueError('Mel contains nan! Using a TTS voice? Add a small epsilon noise to the wav file and try again')\n",
    "\n",
    "    mel_chunks = []\n",
    "    mel_idx_multiplier = 80. / fps\n",
    "    i = 0\n",
    "    while 1:\n",
    "        start_idx = int(i * mel_idx_multiplier)\n",
    "        if start_idx + mel_step_size > len(mel[0]):\n",
    "            mel_chunks.append(mel[:, len(mel[0]) - mel_step_size:])\n",
    "            break\n",
    "        mel_chunks.append(mel[:, start_idx: start_idx + mel_step_size])\n",
    "        i += 1\n",
    "\n",
    "    print(\"Length of mel chunks: {}\".format(len(mel_chunks)))\n",
    "\n",
    "    full_frames = full_frames[:len(mel_chunks)]\n",
    "\n",
    "    batch_size = args['wav2lip_batch_size']\n",
    "    gen = datagen(full_frames.copy(), mel_chunks)\n",
    "\n",
    "    try:\n",
    "        print(\"video generating\")  \n",
    "        for i, (img_batch, mel_batch, frames, coords) in enumerate(tqdm(gen,\n",
    "                                                                        total=int(\n",
    "                                                                            np.ceil(float(len(mel_chunks)) / batch_size)))):\n",
    "            print(\"xyz\")\n",
    "            if i == 0:\n",
    "                model = load_model(args['checkpoint_path'])\n",
    "                print(\"Model loaded\")\n",
    "\n",
    "                frame_h, frame_w = full_frames[0].shape[:-1]\n",
    "                out = cv2.VideoWriter('temp/result.avi',\n",
    "                        cv2.VideoWriter_fourcc(*'DIVX'), fps, (frame_w, frame_h))\n",
    "                img_batch = torch.FloatTensor(np.transpose(img_batch, (0, 3, 1, 2))).to(device)\n",
    "                mel_batch = torch.FloatTensor(np.transpose(mel_batch, (0, 3, 1, 2))).to(device)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    pred = model(mel_batch, img_batch)\n",
    "\n",
    "                pred = pred.cpu().numpy().transpose(0, 2, 3, 1) * 255.\n",
    "\n",
    "                for p, f, c in zip(pred, frames, coords):\n",
    "                    y1, y2, x1, x2 = c\n",
    "                    p = cv2.resize(p.astype(np.uint8), (x2 - x1, y2 - y1))\n",
    "\n",
    "                    f[y1:y2, x1:x2] = p\n",
    "                    out.write(f)  # frames for entire video # 4 -> 4 video frames * 8\n",
    "        out.release()\n",
    "        # command = 'ffmpeg -y -i {} -i {} -strict -2 -q:v 1 {}'.format(args['audio'], 'temp/result.avi', args['outfile'])\n",
    "        # subprocess.call(command, shell=platform.system() != 'Windows')\n",
    "    except:\n",
    "        return 'error'\n",
    "\t\n",
    "    command = 'ffmpeg -y -i {} -i {} -strict -2 -q:v 1 {}'.format(args['audio'], 'temp/result.avi', final_output_directory)\n",
    "    subprocess.call(command, shell=platform.system() != 'Windows')\n",
    "\n",
    "\n",
    "def get_conversion(audio_file, video_file, file_name, checkpoint_path, final_output_directory):\n",
    "    convert(audio_file, video_file, checkpoint_path, final_output_directory)\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "# \tmain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb67feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating video\n",
      "Reading video frames...\n",
      "Number of frames available for inference: 36\n",
      "original audio\n"
     ]
    }
   ],
   "source": [
    "video_file=r\"D:\\PAGO\\sample_data\\uploaded.mp4\"\n",
    "audio_file=r\"D:\\PAGO\\translated_audio\\translated.wav\"\n",
    "final_output_directory=r\"D:\\PAGO\\converted_videos\"\n",
    "checkpoint_path=r\"D:\\PAGO\\Wav2Lip\\checkpoints\\wav2lip_gan.pth\"\n",
    "convert(audio_file, video_file, checkpoint_path, final_output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91251598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu for inference.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from flask import Flask, request, session, send_file, render_template\n",
    "from werkzeug.utils import secure_filename\n",
    "import audio_video_handler\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "\n",
    "app = Flask(__name__, static_folder='static')\n",
    "app.config['SECRET_KEY']=\"abcdefg\"\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/language', methods=['POST'])\n",
    "def translate_text():\n",
    "    try:\n",
    "        selected_language = request.form.get('language')\n",
    "        if selected_language in ['en', 'hi']:  # Add more languages as needed\n",
    "            session['selected_language'] = selected_language\n",
    "            return \"Language selected successfully\"\n",
    "        else:\n",
    "            return \"Invalid language selected\", 400\n",
    "    except KeyError:\n",
    "        return \"No language selected\", 400\n",
    "\n",
    "@app.route('/upload_video', methods=['POST'])\n",
    "def upload_video():\n",
    "    try:\n",
    "        media_folder = \"D:/PAGO/sample_data\"\n",
    "        if not os.path.exists(media_folder):\n",
    "            os.makedirs(media_folder)\n",
    "        file = request.files['videoFile']\n",
    "        filename = secure_filename(file.filename)\n",
    "        extension = pathlib.Path(filename).suffix\n",
    "        filename = 'uploaded' + extension\n",
    "        destination = \"/\".join([media_folder, filename])\n",
    "        file.save(destination)\n",
    "        return 'Video uploaded successfully'\n",
    "    except Exception as e:\n",
    "        return f'Error occurred: {e}', 500\n",
    "\n",
    "\n",
    "@app.route('/generate', methods=['POST'])\n",
    "def generate_result():\n",
    "    try:\n",
    "        print(\"covnerting video .. \")\n",
    "        selected_language = session.get('selected_language')  # Get selected language from session\n",
    "        if not selected_language:\n",
    "            return \"Language not selected. Please select a language first.\", 400\n",
    "        else:\n",
    "            print( \"Language selected\")\n",
    "        # Assuming convert_video accepts the language as an argument\n",
    "        audio_video_handler.convert_video(language=selected_language)\n",
    "        print(\"conversion .. completed .. \")\n",
    "        return render_template('index.html', show_download=True)\n",
    "    except Exception as e:\n",
    "        return f'Error occurred: {e}', 500\n",
    "\n",
    "@app.route('/download_generated_video', methods=['POST'])\n",
    "def get_generated_video():\n",
    "    output_video_path =\"D:/PAGO/converted_videos/output.mp4\" # Replace this with the actual path of the generated video\n",
    "    try:\n",
    "        return send_file(output_video_path, as_attachment=True)\n",
    "    except:\n",
    "        return \"Generated video file not found!\", 404\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, port=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c5b42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import *\n",
    "\n",
    "# This file is dedicated for extracting audio and saving it to a particular file\n",
    "\n",
    "def extract_audio(default_video_file, output_audio_file_location):\n",
    "    clip =  VideoFileClip(default_video_file)\n",
    "    clip.audio.write_audiofile(output_audio_file_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "018c24ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started converting\n",
      "talk_voice_English_hi\n",
      "D:/PAGO/extracted_audio/talk_voice_English_hi.wav\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'speech' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 22\u001b[0m\n\u001b[0;32m     17\u001b[0m     transation_completed \u001b[38;5;241m=\u001b[39m translate_audio(output_audio_file_location,\n\u001b[0;32m     18\u001b[0m                                                                           output_translated_audio_location,\n\u001b[0;32m     19\u001b[0m                                                                           language\n\u001b[0;32m     20\u001b[0m                                                                           )\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msuccess\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 22\u001b[0m convert_video(language,video_file\u001b[38;5;241m=\u001b[39mDEFAULT_VIDEO_FILE, output_audio_file_location\u001b[38;5;241m=\u001b[39mOUTPUT_AUDIO_FILE_LOCATION, output_translated_audio_location\u001b[38;5;241m=\u001b[39mOUTPUT_TRANSLATED_AUDIO_LOCATION, video_file_name\u001b[38;5;241m=\u001b[39mDEFAULT_VIDEO_FILE_NAME , final_output_directory\u001b[38;5;241m=\u001b[39mFINAL_OUTPUT_DIRECTOR)\n",
      "Cell \u001b[1;32mIn[10], line 17\u001b[0m, in \u001b[0;36mconvert_video\u001b[1;34m(language, video_file, output_audio_file_location, output_translated_audio_location, video_file_name, final_output_directory)\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAudio file not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_audio_file_location\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m#     extract_audio_from_video.extract_audio(video_file, output_audio_file_location)\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m#     print(\"audio extracted\")\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m     transation_completed \u001b[38;5;241m=\u001b[39m translate_audio(output_audio_file_location,\n\u001b[0;32m     18\u001b[0m                                                                           output_translated_audio_location,\n\u001b[0;32m     19\u001b[0m                                                                           language\n\u001b[0;32m     20\u001b[0m                                                                           )\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msuccess\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[1;32mIn[8], line 16\u001b[0m, in \u001b[0;36mtranslate_audio\u001b[1;34m(audio_file, output_audio_file_location, langauge)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m io\u001b[38;5;241m.\u001b[39mopen(audio_file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m audio_file:\n\u001b[0;32m     15\u001b[0m     content \u001b[38;5;241m=\u001b[39m audio_file\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m---> 16\u001b[0m     audio \u001b[38;5;241m=\u001b[39m speech\u001b[38;5;241m.\u001b[39mRecognitionAudio(content\u001b[38;5;241m=\u001b[39mcontent)\n\u001b[0;32m     17\u001b[0m audio \u001b[38;5;241m=\u001b[39m whisper\u001b[38;5;241m.\u001b[39mload_audio(audio)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio loaded\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'speech' is not defined"
     ]
    }
   ],
   "source": [
    "import io\n",
    "language = 'hi'\n",
    "def convert_video(language,video_file=DEFAULT_VIDEO_FILE, output_audio_file_location=OUTPUT_AUDIO_FILE_LOCATION, output_translated_audio_location=OUTPUT_TRANSLATED_AUDIO_LOCATION, video_file_name=DEFAULT_VIDEO_FILE_NAME , final_output_directory=FINAL_OUTPUT_DIRECTOR):\n",
    "\n",
    "    print(\"started converting\")\n",
    "    # language_code, voice_name = find_language_code(language)\n",
    "    video_file_name = video_file_name + \"_\" +language\n",
    "    print(video_file_name)\n",
    "    audio_file_id = \"/\" + video_file_name +\".wav\"\n",
    "    output_audio_file_location = output_audio_file_location + audio_file_id\n",
    "    print(output_audio_file_location)\n",
    "    if not os.path.exists(output_audio_file_location):\n",
    "        raise FileNotFoundError(f\"Audio file not found: {output_audio_file_location}\")\n",
    "\n",
    "#     extract_audio_from_video.extract_audio(video_file, output_audio_file_location)\n",
    "#     print(\"audio extracted\")\n",
    "    transation_completed = translate_audio(output_audio_file_location,\n",
    "                                                                          output_translated_audio_location,\n",
    "                                                                          language\n",
    "                                                                          )\n",
    "    return \"success\"\n",
    "convert_video(language,video_file=DEFAULT_VIDEO_FILE, output_audio_file_location=OUTPUT_AUDIO_FILE_LOCATION, output_translated_audio_location=OUTPUT_TRANSLATED_AUDIO_LOCATION, video_file_name=DEFAULT_VIDEO_FILE_NAME , final_output_directory=FINAL_OUTPUT_DIRECTOR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4495cd24",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] The system cannot find the file specified",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m audio_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:/PAGO/extracted_audio/talk_voice_English_hi.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m result \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtranscribe(audio_file, fp16\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\PAGO\\jupyter\\Lib\\site-packages\\whisper\\transcribe.py:133\u001b[0m, in \u001b[0;36mtranscribe\u001b[1;34m(model, audio, verbose, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, condition_on_previous_text, initial_prompt, word_timestamps, prepend_punctuations, append_punctuations, clip_timestamps, hallucination_silence_threshold, **decode_options)\u001b[0m\n\u001b[0;32m    130\u001b[0m     decode_options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfp16\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;66;03m# Pad 30-seconds of silence to the input audio, for slicing\u001b[39;00m\n\u001b[1;32m--> 133\u001b[0m mel \u001b[38;5;241m=\u001b[39m log_mel_spectrogram(audio, model\u001b[38;5;241m.\u001b[39mdims\u001b[38;5;241m.\u001b[39mn_mels, padding\u001b[38;5;241m=\u001b[39mN_SAMPLES)\n\u001b[0;32m    134\u001b[0m content_frames \u001b[38;5;241m=\u001b[39m mel\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m N_FRAMES\n\u001b[0;32m    135\u001b[0m content_duration \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(content_frames \u001b[38;5;241m*\u001b[39m HOP_LENGTH \u001b[38;5;241m/\u001b[39m SAMPLE_RATE)\n",
      "File \u001b[1;32mD:\\PAGO\\jupyter\\Lib\\site-packages\\whisper\\audio.py:140\u001b[0m, in \u001b[0;36mlog_mel_spectrogram\u001b[1;34m(audio, n_mels, padding, device)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_tensor(audio):\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(audio, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 140\u001b[0m         audio \u001b[38;5;241m=\u001b[39m load_audio(audio)\n\u001b[0;32m    141\u001b[0m     audio \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(audio)\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\PAGO\\jupyter\\Lib\\site-packages\\whisper\\audio.py:58\u001b[0m, in \u001b[0;36mload_audio\u001b[1;34m(file, sr)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# fmt: on\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     out \u001b[38;5;241m=\u001b[39m run(cmd, capture_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, check\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mstdout\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CalledProcessError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to load audio: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mdecode()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32mD:\\PAGO\\jupyter\\Lib\\subprocess.py:548\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstdout\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[0;32m    546\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstderr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[1;32m--> 548\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[0;32m    549\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    550\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mcommunicate(\u001b[38;5;28minput\u001b[39m, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n",
      "File \u001b[1;32mD:\\PAGO\\jupyter\\Lib\\subprocess.py:1026\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[0m\n\u001b[0;32m   1022\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_mode:\n\u001b[0;32m   1023\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[0;32m   1024\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m-> 1026\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0;32m   1027\u001b[0m                         pass_fds, cwd, env,\n\u001b[0;32m   1028\u001b[0m                         startupinfo, creationflags, shell,\n\u001b[0;32m   1029\u001b[0m                         p2cread, p2cwrite,\n\u001b[0;32m   1030\u001b[0m                         c2pread, c2pwrite,\n\u001b[0;32m   1031\u001b[0m                         errread, errwrite,\n\u001b[0;32m   1032\u001b[0m                         restore_signals,\n\u001b[0;32m   1033\u001b[0m                         gid, gids, uid, umask,\n\u001b[0;32m   1034\u001b[0m                         start_new_session, process_group)\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m   1036\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr)):\n",
      "File \u001b[1;32mD:\\PAGO\\jupyter\\Lib\\subprocess.py:1538\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session, unused_process_group)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# Start the process\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1538\u001b[0m     hp, ht, pid, tid \u001b[38;5;241m=\u001b[39m _winapi\u001b[38;5;241m.\u001b[39mCreateProcess(executable, args,\n\u001b[0;32m   1539\u001b[0m                              \u001b[38;5;66;03m# no special security\u001b[39;00m\n\u001b[0;32m   1540\u001b[0m                              \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1541\u001b[0m                              \u001b[38;5;28mint\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m close_fds),\n\u001b[0;32m   1542\u001b[0m                              creationflags,\n\u001b[0;32m   1543\u001b[0m                              env,\n\u001b[0;32m   1544\u001b[0m                              cwd,\n\u001b[0;32m   1545\u001b[0m                              startupinfo)\n\u001b[0;32m   1546\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1547\u001b[0m     \u001b[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[0;32m   1548\u001b[0m     \u001b[38;5;66;03m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;66;03m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m     \u001b[38;5;66;03m# ReadFile will hang.\u001b[39;00m\n\u001b[0;32m   1553\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_pipe_fds(p2cread, p2cwrite,\n\u001b[0;32m   1554\u001b[0m                          c2pread, c2pwrite,\n\u001b[0;32m   1555\u001b[0m                          errread, errwrite)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified"
     ]
    }
   ],
   "source": [
    "audio_file=\"D:/PAGO/extracted_audio/talk_voice_English_hi.wav\"\n",
    "result = model.transcribe(audio_file, fp16=False) \n",
    "print(\"result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ffdd4b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:/PAGO/Wav2Lip/media/.wav'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "destination"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
